regression-MNIST字体识别：
1.MNIST数据集简介：由一些手写数字的图片和相应标签组成，图片总共分为10类，分别对应0～9十个数字；每张图片的大小为28×28像素。
标签则由one-hot向量表示，一个one-hot向量除了某一位数字为1外，其余各唯独都是0。比如[1,0,0,0,0,0,0,0,0,0,0]表示数字“0”， [0,0,0,0,0,0,0,0,0,0,1]表示数字“9”，以此类推。

2.下载MNIST数据集

3.将MNIST数据集文件前50张训练图保存成图片

4.Softmax回归介绍：
Softmax回归是一个线性的多类分类模型。对于MNIST数据集的分类问题中，一个有10个类别（0～9），我们希望对输入的图像计算出它属于某个类别的概率，比如属于9的概率是80%，属于1的概率是5%等等，最后模型预测的结果就是概率最大的那个类别。

5.损失函数和优化器
训练模型的输出值和实际值肯定存在一定偏差，这种偏差越小，表示模型预测越准确，而衡量这种偏差的函数就是损失函数。Softmax回归模型中一般使用交叉熵来做损失函数；
交叉熵是判断一个输出向量与期望向量的接近程度的常用方法之一。它是分类问题中使用比较广的一种损失函数；
既然有损失，那么我们肯定就得去优化以减小这个损失。优化损失的函数有很多，我们这里使用梯度下降法。

6.tensorflow代码实现

cnn-MNIST字体识别：
1.卷积神经网络简介：主要由输入层、卷积层、池化层、全连接层和softmax层。
使用全连接神经网络处理图像的最大问题在于全连接层的参数太多。参数增多除了导致计算速度减慢，还很容易导致过拟合问题。而卷积神经网络可以有效的减少神经网络中的参数。

2.神经网络常用结构
2.1卷积层
卷积层中，过滤器所处理的节点矩阵的长和宽都是由人工指定，这个节点矩阵的尺寸被称之为过滤器的尺寸，常用的过滤器尺寸有3×3或5×5，使用ReLU作为激活函数
2.2池化层
池化层可以非常有效地缩小矩阵的尺寸，从而减少最后全连接层中的参数。使用池化层既可以加快计算速度也有防止过拟合问题的作用。采用更加简单的最大值或平均值运算
2.3过拟合
所谓过拟合，指的是当一个模型过为复杂之后，它可以很好的记忆每一个训练数据中随机噪音的部分而忘了要去学习训练数据中的趋势。过度拟合训练数据中的随机噪音虽然可以得到非常小的损失函数，但是对于未知数据可能无法做出可靠的判断。

3.tensorflow代码实现


